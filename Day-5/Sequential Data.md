Sequential data refers to a type of data where the order of elements matters. It represents a series of values or observations arranged in a specific sequence. This data format is commonly encountered in various fields, including time series analysis, natural language processing, genomics, and more.

In sequential data, the relationship between elements is often temporal or contextual. Each element's position in the sequence can hold valuable information, and analyzing sequential patterns is crucial for understanding trends, making predictions, and extracting meaningful insights from the data. Techniques like recurrent neural networks (RNNs) and transformers are commonly used to handle and process sequential data effectively.
![[Pasted image 20230818151347.png]]
Name Entity Recognition
![[Pasted image 20230818152536.png]]

Why not just use normal neural network for NLP?
Using a Recurrent Neural Network (RNN) over a traditional feedforward neural network for Natural Language Processing (NLP) tasks addresses several deficiencies that arise due to the sequential and contextual nature of language. Here are some key shortcomings of using a regular feedforward network for NLP and how RNNs overcome them:

1. **Variable-Length Input:** Traditional networks require fixed input sizes, making them unsuitable for handling variable-length sequences like sentences. RNNs, on the other hand, can process sequences of varying lengths, making them well-suited for NLP tasks where input length varies.
    
2. **Contextual Information:** Feedforward networks treat inputs independently, disregarding the contextual dependencies between words in sentences. RNNs are designed to capture sequential dependencies, allowing them to understand the contextual relationship between words, which is crucial for language understanding.
    
3. **Parameter Sharing:** In feedforward networks, parameters are not shared across different time steps or positions in the sequence. RNNs use shared weights across time steps, which enables them to capture patterns that repeat throughout the sequence.
    
4. **Short-Term Memory:** Traditional networks have limited short-term memory, which makes them inadequate for tasks that involve maintaining and using context over longer sequences. RNNs have an inherent memory mechanism that enables them to remember information from previous time steps and use it for making predictions.
    
5. **Vanishing Gradient Problem:** When training deep networks with many layers, the gradient can become too small, leading to slow or stalled learning. RNNs are designed with mechanisms like LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit) cells that mitigate the vanishing gradient problem, allowing for more effective training of deep architectures.
    
6. **Sequential Data Processing:** Traditional networks process input data all at once, treating it as a fixed input. RNNs process sequential data step by step, allowing them to maintain memory of previous steps' computations and make decisions based on cumulative context.
    
7. **Sequential Output Generation:** NLP tasks often involve generating sequences of output, such as in language translation or text generation. RNNs are well-suited for this due to their ability to produce one element at a time while considering previous outputs.


RNN PIPELINE
![[Pasted image 20230818155106.png]]

![[Pasted image 20230818190404.png]]

GRU
![[Pasted image 20230818202819.png]]
At its core, a GRU is a type of recurrent neural network (RNN) designed to capture and model sequences of data, such as sentences in natural language or time series data. GRUs are particularly effective in handling long-range dependencies within sequences, making them suitable for tasks like language modeling, machine translation, and more.

Here's a simplified explanation of how a GRU works:

1. **Introduction to Recurrent Neural Networks (RNNs):** Imagine you're processing a sentence word by word. An RNN processes each word in the sentence one at a time and maintains an internal state (also known as hidden state) that captures information from previous words. This state is updated and passed along as new words are input.
    
2. **Problem of Vanishing and Exploding Gradients:** Traditional RNNs have an issue with vanishing and exploding gradients, which means that the information from earlier words can either fade away or grow excessively as it's passed through the network. This can lead to difficulties in capturing long-range dependencies.
    
3. **Introducing GRU:** A GRU is an improvement over traditional RNNs that helps address the vanishing gradient problem and improve the learning of long-range dependencies. It does this through the use of two mechanisms: an update gate and a reset gate.
    
4. **Update Gate:** The update gate decides how much of the previous internal state should be mixed with the current input to compute the new internal state. It considers the previous hidden state and the current input to generate a value between 0 and 1. This value determines the balance between keeping the old information and incorporating new information.
    
5. **Reset Gate:** The reset gate determines how much of the previous internal state should be forgotten or "reset" when computing the new internal state. It also considers the previous hidden state and the current input to produce a value between 0 and 1.
    
6. **Calculating New Hidden State:** Using the update and reset gates, the GRU calculates a new internal state that balances old information, new input, and what to forget from the previous state. This new internal state is then passed to the next time step.
    
7. **Output Generation:** The new internal state can also be used to generate the output of the current time step, which can be used for various tasks such as predicting the next word in a sentence.


LSTM
![[Pasted image 20230818211600.png]]

Bi-Directional RNN
![[Pasted image 20230818223631.png]]


## Â Long Short-Term Memory (LSTM) Network
![[Pasted image 20230819000506.png]]
### Overview of gates and states

#### Forget gateÂ ğšªğ‘“

- Let's assume you are reading words in a piece of text, and plan to use an LSTM to keep track of grammatical structures, such as whether the subject is singular ("puppy") or plural ("puppies").
- If the subject changes its state (from a singular word to a plural word), the memory of the previous state becomes outdated, so you'll "forget" that outdated state.
- The "forget gate" is a tensor containing values between 0 and 1.
    - If a unit in the forget gate has a value close to 0, the LSTM will "forget" the stored state in the corresponding unit of the previous cell state.
    - If a unit in the forget gate has a value close to 1, the LSTM will mostly remember the corresponding value in the stored state.

##### Equation
![[Pasted image 20230819000559.png]]
##### Explanation of the equation:

- ğ–ğŸï¿½ï¿½Â contains weights that govern the forget gate's behavior.
- The previous time step's hidden stateÂ [ğ‘âŸ¨ğ‘¡âˆ’1âŸ©[ï¿½âŸ¨ï¿½âˆ’1âŸ©Â and current time step's inputÂ ğ‘¥âŸ¨ğ‘¡âŸ©]ï¿½âŸ¨ï¿½âŸ©]Â are concatenated together and multiplied byÂ ğ–ğŸï¿½ï¿½.
- A sigmoid function is used to make each of the gate tensor's valuesÂ ğšªâŸ¨ğ‘¡âŸ©ğ‘“ï¿½ï¿½âŸ¨ï¿½âŸ©Â range from 0 to 1.
- The forget gateÂ ğšªâŸ¨ğ‘¡âŸ©ğ‘“ï¿½ï¿½âŸ¨ï¿½âŸ©Â has the same dimensions as the previous cell stateÂ ğ‘âŸ¨ğ‘¡âˆ’1âŸ©ï¿½âŸ¨ï¿½âˆ’1âŸ©.
- This means that the two can be multiplied together, element-wise.
- Multiplying the tensorsÂ ğšªâŸ¨ğ‘¡âŸ©ğ‘“âˆ—ğœâŸ¨ğ‘¡âˆ’1âŸ©ï¿½ï¿½âŸ¨ï¿½âŸ©âˆ—ï¿½âŸ¨ï¿½âˆ’1âŸ©Â is like applying a mask over the previous cell state.
- If a single value inÂ ğšªâŸ¨ğ‘¡âŸ©ğ‘“ï¿½ï¿½âŸ¨ï¿½âŸ©Â is 0 or close to 0, then the product is close to 0.
    - This keeps the information stored in the corresponding unit inÂ ğœâŸ¨ğ‘¡âˆ’1âŸ©ï¿½âŸ¨ï¿½âˆ’1âŸ©Â from being remembered for the next time step.
- Similarly, if one value is close to 1, the product is close to the original value in the previous cell state.
    - The LSTM will keep the information from the corresponding unit ofÂ ğœâŸ¨ğ‘¡âˆ’1âŸ©ï¿½âŸ¨ï¿½âˆ’1âŸ©, to be used in the next time step.

##### Variable names in the code
The variable names in the code are similar to the equations, with slight differences.

- `Wf`: forget gate weightÂ ğ–ğ‘“
- `bf`: forget gate biasÂ ğ›ğ‘“
- `ft`: forget gateÂ Î“âŸ¨ğ‘¡âŸ©ğ‘“Î“

#### Candidate valueÂ ğœÌƒÂ âŸ¨ğ‘¡âŸ©

- The candidate value is a tensor containing information from the current time step thatÂ **may**Â be stored in the current cell stateÂ ğœâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©.
- The parts of the candidate value that get passed on depend on the update gate.
- The candidate value is a tensor containing values that range from -1 to 1.
- The tilde "~" is used to differentiate the candidateÂ ğœÌƒÂ âŸ¨ğ‘¡âŸ©ï¿½~âŸ¨ï¿½âŸ©Â from the cell stateÂ ğœâŸ¨ğ‘¡âŸ©

##### Equation[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Equation)

![[Pasted image 20230819000639.png]]
##### Explanation of the equation[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Explanation-of-the-equation)

- TheÂ _tanh_Â function produces values between -1 and 1.

##### Variable names in the code

- `cct`: candidate valueÂ ğœÌƒÂ âŸ¨ğ‘¡âŸ©

#### Update gateÂ ğšªğ‘–

- You use the update gate to decide what aspects of the candidateÂ ğœÌƒÂ âŸ¨ğ‘¡âŸ©ï¿½~âŸ¨ï¿½âŸ©Â to add to the cell stateÂ ğ‘âŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©.
- The update gate decides what parts of a "candidate" tensorÂ ğœÌƒÂ âŸ¨ğ‘¡âŸ©ï¿½~âŸ¨ï¿½âŸ©Â are passed onto the cell stateÂ ğœâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©.
- The update gate is a tensor containing values between 0 and 1.
    - When a unit in the update gate is close to 1, it allows the value of the candidateÂ ğœÌƒÂ âŸ¨ğ‘¡âŸ©ï¿½~âŸ¨ï¿½âŸ©Â to be passed onto the hidden stateÂ ğœâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©
    - When a unit in the update gate is close to 0, it prevents the corresponding value in the candidate from being passed onto the hidden state.
- Notice that the subscript "i" is used and not "u", to follow the convention used in the literature.

##### Equation[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Equation)

![[Pasted image 20230819000703.png]]
##### Explanation of the equation

- Similar to the forget gate, hereÂ ğšªâŸ¨ğ‘¡âŸ©ğ‘–ï¿½ï¿½âŸ¨ï¿½âŸ©, the sigmoid produces values between 0 and 1.
- The update gate is multiplied element-wise with the candidate, and this product (ğšªâŸ¨ğ‘¡âŸ©ğ‘–âˆ—ğ‘ÌƒÂ âŸ¨ğ‘¡âŸ©ï¿½ï¿½âŸ¨ï¿½âŸ©âˆ—ï¿½~âŸ¨ï¿½âŸ©) is used in determining the cell stateÂ ğœâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©.

##### Variable names in code (Please note that they're different than the equations)[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Variable-names-in-code-(Please-note-that-they're-different-than-the-equations))

In the code, you'll use the variable names found in the academic literature. These variables don't use "u" to denote "update".

- `Wi`Â is the update gate weightÂ ğ–ğ‘–ï¿½ï¿½Â (not "Wu")
- `bi`Â is the update gate biasÂ ğ›ğ‘–ï¿½ï¿½Â (not "bu")
- `it`Â is the update gateÂ ğšªâŸ¨ğ‘¡âŸ©ğ‘–ï¿½ï¿½âŸ¨ï¿½âŸ©Â (not "ut")

#### Cell stateÂ ğœâŸ¨ğ‘¡âŸ©

- The cell state is the "memory" that gets passed onto future time steps.
- The new cell stateÂ ğœâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©Â is a combination of the previous cell state and the candidate value.

##### Equation[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Equation)

![[Pasted image 20230819000729.png]]
##### Explanation of equation[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Explanation-of-equation)

- The previous cell stateÂ ğœâŸ¨ğ‘¡âˆ’1âŸ©ï¿½âŸ¨ï¿½âˆ’1âŸ©Â is adjusted (weighted) by the forget gateÂ ğšªâŸ¨ğ‘¡âŸ©ğ‘“ï¿½ï¿½âŸ¨ï¿½âŸ©
- and the candidate valueÂ ğœÌƒÂ âŸ¨ğ‘¡âŸ©ï¿½~âŸ¨ï¿½âŸ©, adjusted (weighted) by the update gateÂ ğšªâŸ¨ğ‘¡âŸ©ğ‘–ï¿½ï¿½âŸ¨ï¿½âŸ©

##### Variable names and shapes in the code[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Variable-names-and-shapes-in-the-code)

- `c`: cell state, including all time steps,Â ğœï¿½Â shapeÂ (ğ‘›ğ‘,ğ‘š,ğ‘‡ğ‘¥)
- `c_next`: new (next) cell state,Â ğœâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©Â shapeÂ (ğ‘›ğ‘,ğ‘š)
- `c_prev`: previous cell state,Â ğœâŸ¨ğ‘¡âˆ’1âŸ©ï¿½âŸ¨ï¿½âˆ’1âŸ©, shapeÂ (ğ‘›ğ‘,ğ‘š)

#### Output gateÂ ğšªğ‘œï¿½ï¿½[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Output-gate-$\mathbf{\Gamma}_{o}$)

- The output gate decides what gets sent as the prediction (output) of the time step.
- The output gate is like the other gates, in that it contains values that range from 0 to 1.

##### Equation

![[Pasted image 20230819000757.png]]
##### Explanation of the equation[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Explanation-of-the-equation)

- The output gate is determined by the previous hidden stateÂ ğšâŸ¨ğ‘¡âˆ’1âŸ©ï¿½âŸ¨ï¿½âˆ’1âŸ©Â and the current inputÂ ğ±âŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©
- The sigmoid makes the gate range from 0 to 1.

##### Variable names in the code[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Variable-names-in-the-code)

- `Wo`: output gate weight,Â ğ–ğ¨ï¿½ï¿½
- `bo`: output gate bias,Â ğ›ğ¨ï¿½ï¿½
- `ot`: output gate,Â ğšªâŸ¨ğ‘¡âŸ©ğ‘œï¿½ï¿½âŸ¨ï¿½âŸ©

#### Hidden stateÂ ğšâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Hidden-state-$\mathbf{a}^{\langle-t-\rangle}$)

- The hidden state gets passed to the LSTM cell's next time step.
- It is used to determine the three gates (ğšªğ‘“,ğšªğ‘¢,ğšªğ‘œï¿½ï¿½,ï¿½ï¿½,ï¿½ï¿½) of the next time step.
- The hidden state is also used for the predictionÂ ğ‘¦âŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©.

##### Equation[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Equation)

![[Pasted image 20230819000814.png]]
##### Explanation of equation[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Explanation-of-equation)

- The hidden stateÂ ğšâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©Â is determined by the cell stateÂ ğœâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©Â in combination with the output gateÂ ğšªğ‘œï¿½ï¿½.
- The cell state state is passed through theÂ `tanh`Â function to rescale values between -1 and 1.
- The output gate acts like a "mask" that either preserves the values ofÂ tanh(ğœâŸ¨ğ‘¡âŸ©)tanhâ¡(ï¿½âŸ¨ï¿½âŸ©)Â or keeps those values from being included in the hidden stateÂ ğšâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©

##### Variable names and shapes in the code[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Variable-names--and-shapes-in-the-code)

- `a`: hidden state, including time steps.Â ğšï¿½Â has shapeÂ (ğ‘›ğ‘,ğ‘š,ğ‘‡ğ‘¥)(ï¿½ï¿½,ï¿½,ï¿½ï¿½)
- `a_prev`: hidden state from previous time step.Â ğšâŸ¨ğ‘¡âˆ’1âŸ©ï¿½âŸ¨ï¿½âˆ’1âŸ©Â has shapeÂ (ğ‘›ğ‘,ğ‘š)(ï¿½ï¿½,ï¿½)
- `a_next`: hidden state for next time step.Â ğšâŸ¨ğ‘¡âŸ©ï¿½âŸ¨ï¿½âŸ©Â has shapeÂ (ğ‘›ğ‘,ğ‘š)(ï¿½ï¿½,ï¿½)

#### PredictionÂ ğ²âŸ¨ğ‘¡âŸ©ğ‘ğ‘Ÿğ‘’ğ‘‘

- The prediction in this use case is a classification, so you'll use a softmax.

The equation is:

ğ²âŸ¨ğ‘¡âŸ©ğ‘ğ‘Ÿğ‘’ğ‘‘=softmax(ğ–ğ‘¦ğšâŸ¨ğ‘¡âŸ©+ğ›ğ‘¦)ï¿½ï¿½ï¿½ï¿½ï¿½âŸ¨ï¿½âŸ©=softmax(ï¿½ï¿½ï¿½âŸ¨ï¿½âŸ©+ï¿½ï¿½)

##### Variable names and shapes in the code[](https://useaapvuptka.labs.coursera.org/notebooks/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb#Variable-names-and-shapes-in-the-code)

- `y_pred`: prediction, including all time steps.Â ğ²ğ‘ğ‘Ÿğ‘’ğ‘‘ï¿½ï¿½ï¿½ï¿½ï¿½Â has shapeÂ (ğ‘›ğ‘¦,ğ‘š,ğ‘‡ğ‘¥)(ï¿½ï¿½,ï¿½,ï¿½ï¿½). Note thatÂ (ğ‘‡ğ‘¦=ğ‘‡ğ‘¥)(ï¿½ï¿½=ï¿½ï¿½)Â for this example.
- `yt_pred`: prediction for the current time stepÂ ğ‘¡ï¿½.Â ğ²âŸ¨ğ‘¡âŸ©ğ‘ğ‘Ÿğ‘’ğ‘‘ï¿½ï¿½ï¿½ï¿½ï¿½âŸ¨ï¿½âŸ©Â has shapeÂ (ğ‘›ğ‘¦,ğ‘š)